// AI Agent Service
// à¹ƒà¸Šà¹‰ AI à¸Šà¹ˆà¸§à¸¢à¹à¸à¸°à¸‚à¹‰à¸­à¸¡à¸¹à¸¥, à¸ˆà¸±à¸”à¸£à¸°à¹€à¸šà¸µà¸¢à¸š, validate

const aiService = require('./aiService');
const scrapingService = require('./scrapingService');
const googleMapsService = require('./googleMapsService');
const { db, pool } = require('../database');
const { v4: uuidv4 } = require('uuid');

// Helper function to parse Facebook post date (e.g., "5 à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡", "1 à¸§à¸±à¸™", "2 à¸§à¸±à¸™")
function parsePostDate(postDateStr) {
  if (!postDateStr) return null;

  const now = new Date();
  const dateStr = postDateStr.toLowerCase().trim();

  // Match patterns like "5 à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡", "1 à¸§à¸±à¸™", "2 à¸§à¸±à¸™", "3 à¸ªà¸±à¸›à¸”à¸²à¸«à¹Œ", "1 à¹€à¸”à¸·à¸­à¸™"
  const hourMatch = dateStr.match(/(\d+)\s*à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡/);
  if (hourMatch) {
    const hours = parseInt(hourMatch[1]);
    const date = new Date(now);
    date.setHours(date.getHours() - hours);
    return date;
  }

  const dayMatch = dateStr.match(/(\d+)\s*à¸§à¸±à¸™/);
  if (dayMatch) {
    const days = parseInt(dayMatch[1]);
    const date = new Date(now);
    date.setDate(date.getDate() - days);
    return date;
  }

  const weekMatch = dateStr.match(/(\d+)\s*à¸ªà¸±à¸›à¸”à¸²à¸«à¹Œ/);
  if (weekMatch) {
    const weeks = parseInt(weekMatch[1]);
    const date = new Date(now);
    date.setDate(date.getDate() - (weeks * 7));
    return date;
  }

  const monthMatch = dateStr.match(/(\d+)\s*à¹€à¸”à¸·à¸­à¸™/);
  if (monthMatch) {
    const months = parseInt(monthMatch[1]);
    const date = new Date(now);
    date.setMonth(date.getMonth() - months);
    return date;
  }

  // If can't parse, assume it's recent (within 30 days)
  return now;
}

class AgentService {
  // Scrape website and extract plant data using AI
  async scrapeWebsite(websiteId, url) {
    try {
      console.log(`ðŸ¤– AI Agent: Starting scrape for ${url}`);

      // 1. Scrape HTML content
      const scrapeResult = await scrapingService.scrapeHTML(url);
      if (!scrapeResult.success) {
        const errorMsg = scrapeResult.error || 'Unknown error';
        console.error(`âŒ Scraping failed: ${errorMsg}`);

        // Check if it's a Facebook URL and provide helpful error message
        const isFacebook = url.includes('facebook.com') || url.includes('fb.com');
        if (isFacebook) {
          throw new Error(`à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸– scrape Facebook à¹„à¸”à¹‰: ${errorMsg}\n\nðŸ’¡ à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸: Facebook à¸¡à¸µà¸£à¸°à¸šà¸šà¸›à¹‰à¸­à¸‡à¸à¸±à¸™ bot à¸—à¸µà¹ˆà¹à¸‚à¹‡à¸‡à¹à¸à¸£à¹ˆà¸‡ à¸­à¸²à¸ˆà¸•à¹‰à¸­à¸‡:\n- à¹ƒà¸Šà¹‰ Puppeteer (à¸•à¹‰à¸­à¸‡à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ Chromium)\n- à¹ƒà¸Šà¹‰ Facebook Graph API (à¸•à¹‰à¸­à¸‡à¸¡à¸µ Access Token)\n- à¸«à¸£à¸·à¸­à¸¥à¸­à¸‡à¹ƒà¸Šà¹‰ URL à¸­à¸·à¹ˆà¸™`);
        }

        throw new Error(`Failed to scrape: ${errorMsg}`);
      }

      console.log(`âœ… Scraping successful: ${scrapeResult.method}, HTML length: ${scrapeResult.html.length}`);

      // 2. Extract text content
      const textResult = await scrapingService.extractText(scrapeResult.html);
      if (!textResult.success) {
        throw new Error(`Failed to extract text: ${textResult.error}`);
      }

      // 3. Extract structured data (basic) - à¸£à¸§à¸¡à¸£à¸¹à¸›à¸ à¸²à¸žà¸”à¹‰à¸§à¸¢
      const structuredResult = await scrapingService.extractStructuredData(scrapeResult.html);

      // à¹€à¸à¹‡à¸š URL à¸£à¸¹à¸›à¸ à¸²à¸žà¸ªà¸³à¸«à¸£à¸±à¸šà¸ªà¹ˆà¸‡à¹ƒà¸«à¹‰ AI
      const imageUrls = structuredResult.data?.images?.slice(0, 10).map(img => img.src).filter(src => src && !src.startsWith('data:')).join(', ') || '';

      // 4. Use AI to analyze and extract plant data
      // Check if it's Facebook
      const isFacebook = url.includes('facebook.com') || url.includes('fb.com');
      const isFacebookProfile = url.includes('/user/') || url.includes('/profile.php');
      const sourceType = isFacebookProfile ? 'Facebook Profile (à¹€à¸ˆà¹‰à¸²à¸‚à¸­à¸‡à¸ªà¸§à¸™)' : (isFacebook ? 'Facebook Group/Page' : 'à¹€à¸§à¹‡à¸šà¹„à¸‹à¸•à¹Œ');

      const aiPrompt = `à¸„à¸¸à¸“à¹€à¸›à¹‡à¸™ AI Agent à¸—à¸µà¹ˆà¸Šà¹ˆà¸§à¸¢à¹à¸à¸°à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸•à¹‰à¸™à¹„à¸¡à¹‰à¹à¸¥à¸°à¸£à¸²à¸„à¸²à¸ˆà¸²à¸${sourceType}

à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸${sourceType}:
URL: ${url}
Title: ${structuredResult.data?.title || 'N/A'}
Text Content: ${textResult.text.substring(0, 8000)}... (truncated)
${imageUrls ? `\nà¸£à¸¹à¸›à¸ à¸²à¸žà¸—à¸µà¹ˆà¸žà¸š: ${imageUrls}` : ''}

${isFacebookProfile ? `âš ï¸ à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸: à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸™à¸µà¹‰à¸¡à¸²à¸ˆà¸²à¸ Facebook Profile à¸‚à¸­à¸‡à¹€à¸ˆà¹‰à¸²à¸‚à¸­à¸‡à¸ªà¸§à¸™/à¸œà¸¹à¹‰à¸‚à¸²à¸¢

ðŸŽ¯ à¸ªà¸³à¸„à¸±à¸à¸¡à¸²à¸: 
- à¹à¸à¸°à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸‰à¸žà¸²à¸°à¸ˆà¸²à¸à¹‚à¸žà¸ªà¸•à¹Œà¸¥à¹ˆà¸²à¸ªà¸¸à¸” (à¹„à¸¡à¹ˆà¹€à¸à¸´à¸™ 30 à¸§à¸±à¸™) à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™
- à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¸±à¸™à¸—à¸µà¹ˆà¸‚à¸­à¸‡à¹‚à¸žà¸ªà¸•à¹Œà¸à¹ˆà¸­à¸™à¹à¸à¸°à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ (à¸–à¹‰à¸²à¸¡à¸µ "5 à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡", "1 à¸§à¸±à¸™", "2 à¸§à¸±à¸™" à¹€à¸›à¹‡à¸™à¸•à¹‰à¸™)
- à¸–à¹‰à¸²à¹‚à¸žà¸ªà¸•à¹Œà¹€à¸à¹ˆà¸²à¸à¸§à¹ˆà¸² 30 à¸§à¸±à¸™ à¹ƒà¸«à¹‰à¸‚à¹‰à¸²à¸¡à¹„à¸›
- à¹€à¸à¹‡à¸šà¹€à¸‰à¸žà¸²à¸°à¹‚à¸žà¸ªà¸•à¹Œà¸—à¸µà¹ˆà¹ƒà¸«à¸¡à¹ˆà¸—à¸µà¹ˆà¸ªà¸¸à¸” (à¸¥à¹ˆà¸²à¸ªà¸¸à¸”à¸à¹ˆà¸­à¸™)

à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸žà¸š:
- à¸Šà¸·à¹ˆà¸­à¸•à¹‰à¸™à¹„à¸¡à¹‰ (à¸ˆà¸²à¸à¹‚à¸žà¸ªà¸•à¹Œ/à¸£à¸¹à¸›à¸ à¸²à¸ž)
- à¹€à¸šà¸­à¸£à¹Œà¹‚à¸—à¸£à¸¨à¸±à¸žà¸—à¹Œ (à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸•à¸´à¸”à¸•à¹ˆà¸­)
- à¸£à¸¹à¸›à¸ à¸²à¸žà¸•à¹‰à¸™à¹„à¸¡à¹‰ (à¸­à¸²à¸ˆà¹„à¸¡à¹ˆà¸¡à¸µà¸£à¸²à¸„à¸²)
- à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸•à¸´à¸”à¸•à¹ˆà¸­ (à¸Šà¸·à¹ˆà¸­ à¹€à¸šà¸­à¸£à¹Œà¹‚à¸—à¸£ à¸—à¸µà¹ˆà¸­à¸¢à¸¹à¹ˆ)
- à¸§à¸±à¸™à¸—à¸µà¹ˆà¹‚à¸žà¸ªà¸•à¹Œ (à¸–à¹‰à¸²à¸¡à¸µ à¹€à¸Šà¹ˆà¸™ "5 à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡", "1 à¸§à¸±à¸™", "2 à¸§à¸±à¸™")

âš ï¸ à¸£à¸²à¸„à¸²à¸­à¸²à¸ˆà¹„à¸¡à¹ˆà¸¡à¸µ: à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µà¸£à¸²à¸„à¸² à¹ƒà¸«à¹‰à¹ƒà¸ªà¹ˆ price à¹€à¸›à¹‡à¸™ null à¸«à¸£à¸·à¸­ 0
âš ï¸ à¹€à¸à¹‡à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸•à¹‰à¸™à¹„à¸¡à¹‰à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸—à¸µà¹ˆà¸žà¸š: à¹à¸¡à¹‰à¹„à¸¡à¹ˆà¸¡à¸µà¸£à¸²à¸„à¸²à¸à¹‡à¹€à¸à¹‡à¸šà¹„à¸§à¹‰ à¹à¸•à¹ˆà¸•à¹‰à¸­à¸‡à¹€à¸›à¹‡à¸™à¹‚à¸žà¸ªà¸•à¹Œà¸¥à¹ˆà¸²à¸ªà¸¸à¸” (à¹„à¸¡à¹ˆà¹€à¸à¸´à¸™ 30 à¸§à¸±à¸™) à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™` : ''}

${isFacebook && !isFacebookProfile ? 'âš ï¸ à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸: à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸™à¸µà¹‰à¸¡à¸²à¸ˆà¸²à¸ Facebook Group/Page à¸­à¸²à¸ˆà¸¡à¸µà¸£à¸¹à¸›à¹à¸šà¸šà¸—à¸µà¹ˆà¹à¸•à¸à¸•à¹ˆà¸²à¸‡à¸ˆà¸²à¸à¹€à¸§à¹‡à¸šà¹„à¸‹à¸•à¹Œà¸›à¸à¸•à¸´ à¸à¸£à¸¸à¸“à¸²à¹à¸à¸°à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸à¹‚à¸žà¸ªà¸•à¹Œà¸«à¸£à¸·à¸­à¸„à¸­à¸¡à¹€à¸¡à¸™à¸•à¹Œà¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡à¸à¸±à¸šà¸•à¹‰à¸™à¹„à¸¡à¹‰à¹à¸¥à¸°à¸£à¸²à¸„à¸²' : ''}

à¸à¸£à¸¸à¸“à¸²à¹à¸à¸°à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸•à¹‰à¸™à¹„à¸¡à¹‰à¹à¸¥à¸°à¸£à¸²à¸„à¸²à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸‚à¹‰à¸²à¸‡à¸•à¹‰à¸™ à¹à¸¥à¸°à¹à¸›à¸¥à¸‡à¹€à¸›à¹‡à¸™ JSON format à¸•à¸²à¸¡à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¸™à¸µà¹‰:

{
  "supplier": {
    "name": "à¸Šà¸·à¹ˆà¸­à¸£à¹‰à¸²à¸™à¸„à¹‰à¸²/à¹€à¸ˆà¹‰à¸²à¸‚à¸­à¸‡à¸ªà¸§à¸™",
    "location": "à¸—à¸µà¹ˆà¸­à¸¢à¸¹à¹ˆ (à¸–à¹‰à¸²à¸¡à¸µ)",
    "phone": "à¹€à¸šà¸­à¸£à¹Œà¹‚à¸—à¸£ (à¸–à¹‰à¸²à¸¡à¸µ)",
    "website": "${url}"
  },
      "plants": [
    {
      "name": "à¸Šà¸·à¹ˆà¸­à¸•à¹‰à¸™à¹„à¸¡à¹‰",
      "scientificName": "à¸Šà¸·à¹ˆà¸­à¸§à¸´à¸—à¸¢à¸²à¸¨à¸²à¸ªà¸•à¸£à¹Œ (à¸–à¹‰à¸²à¸¡à¸µ)",
      "category": "à¸«à¸¡à¸§à¸”à¸«à¸¡à¸¹à¹ˆ (à¹„à¸¡à¹‰à¸›à¸£à¸°à¸”à¸±à¸š, à¹„à¸¡à¹‰à¸¥à¹‰à¸­à¸¡, à¹„à¸¡à¹‰à¸”à¸­à¸, à¹„à¸¡à¹‰à¹ƒà¸š, à¹à¸„à¸„à¸•à¸±à¸ª, à¸šà¸­à¸™à¹„à¸‹, à¸à¸¥à¹‰à¸§à¸¢à¹„à¸¡à¹‰)",
      "price": à¸£à¸²à¸„à¸² (à¸•à¸±à¸§à¹€à¸¥à¸‚ à¸«à¸£à¸·à¸­ null à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µà¸£à¸²à¸„à¸²),
      "size": "à¸‚à¸™à¸²à¸” (à¸–à¹‰à¸²à¸¡à¸µ)",
      "description": "à¸„à¸³à¸­à¸˜à¸´à¸šà¸²à¸¢ (à¸–à¹‰à¸²à¸¡à¸µ)",
      "imageUrl": "URL à¸£à¸¹à¸›à¸ à¸²à¸žà¸•à¹‰à¸™à¹„à¸¡à¹‰ (à¸–à¹‰à¸²à¸¡à¸µ)",
      "postDate": "à¸§à¸±à¸™à¸—à¸µà¹ˆà¹‚à¸žà¸ªà¸•à¹Œ (à¸–à¹‰à¸²à¸¡à¸µ à¹€à¸Šà¹ˆà¸™ '5 à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡', '1 à¸§à¸±à¸™', '2 à¸§à¸±à¸™')",
      "stockAvailable": true/false (à¸–à¹‰à¸²à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹„à¸”à¹‰)
    }
  ],
  "confidence": 0.0-1.0 (à¸„à¸§à¸²à¸¡à¸¡à¸±à¹ˆà¸™à¹ƒà¸ˆà¹ƒà¸™à¸à¸²à¸£à¹à¸à¸°à¸‚à¹‰à¸­à¸¡à¸¹à¸¥)
}

âš ï¸ à¸ªà¸³à¸„à¸±à¸: à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µà¸£à¸²à¸„à¸² à¹ƒà¸«à¹‰à¹ƒà¸ªà¹ˆ price à¹€à¸›à¹‡à¸™ null à¸«à¸£à¸·à¸­ 0 (à¸«à¹‰à¸²à¸¡à¹ƒà¸ªà¹ˆà¸£à¸²à¸„à¸²à¹à¸šà¸šà¸ªà¸¸à¹ˆà¸¡)
âš ï¸ à¹€à¸à¹‡à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸•à¹‰à¸™à¹„à¸¡à¹‰à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸—à¸µà¹ˆà¸žà¸š à¹à¸¡à¹‰à¹„à¸¡à¹ˆà¸¡à¸µà¸£à¸²à¸„à¸²à¸à¹‡à¹€à¸à¹‡à¸šà¹„à¸§à¹‰

à¸•à¸­à¸šà¹€à¸›à¹‡à¸™ JSON à¸¥à¹‰à¸§à¸™à¹† à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™ à¸«à¹‰à¸²à¸¡à¹ƒà¸ªà¹ˆà¹‚à¸„à¹‰à¸”à¸šà¸¥à¹‡à¸­à¸ (à¹€à¸Šà¹ˆà¸™ code fences) à¸«à¸£à¸·à¸­à¸„à¸³à¸­à¸˜à¸´à¸šà¸²à¸¢à¸­à¸·à¹ˆà¸™à¹†`;

      const aiResult = await aiService.analyzeText(aiPrompt);

      if (!aiResult || !aiResult.plants) {
        throw new Error('AI failed to extract plant data');
      }

      // 5. Validate and clean data using AI
      const validatedData = await this.validateAndCleanData(aiResult);

      // 6. Save to database
      const savedData = await this.saveScrapingResults(websiteId, url, validatedData);

      return {
        success: true,
        data: savedData,
        rawData: {
          htmlLength: scrapeResult.html.length,
          textLength: textResult.text.length,
          method: scrapeResult.method
        }
      };

    } catch (error) {
      console.error('âŒ AI Agent Error:', error);
      throw error;
    }
  }

  // Use AI to validate and clean extracted data
  async validateAndCleanData(extractedData) {
    try {
      const validationPrompt = `à¸„à¸¸à¸“à¹€à¸›à¹‡à¸™ AI Agent à¸—à¸µà¹ˆà¸Šà¹ˆà¸§à¸¢à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹à¸¥à¸°à¸ˆà¸±à¸”à¸£à¸°à¹€à¸šà¸µà¸¢à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸•à¹‰à¸™à¹„à¸¡à¹‰

à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹à¸à¸°à¸¡à¸²à¹„à¸”à¹‰:
${JSON.stringify(extractedData, null, 2)}

ðŸŽ¯ à¸à¸£à¸¸à¸“à¸²à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹à¸¥à¸°à¸ˆà¸±à¸”à¸£à¸°à¹€à¸šà¸µà¸¢à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¹‰à¸„à¸£à¸šà¸–à¹‰à¸§à¸™à¹à¸¥à¸°à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡:

1. **à¸Šà¸·à¹ˆà¸­à¸•à¹‰à¸™à¹„à¸¡à¹‰**: à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹à¸¥à¸°à¹à¸à¹‰à¹„à¸‚à¹ƒà¸«à¹‰à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡ (à¹ƒà¸Šà¹‰à¸Šà¸·à¹ˆà¸­à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸à¸±à¸™à¸—à¸±à¹ˆà¸§à¹„à¸›)
2. **à¸Šà¸·à¹ˆà¸­à¸£à¹‰à¸²à¸™/Supplier**: à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸Šà¸·à¹ˆà¸­à¸£à¹‰à¸²à¸™à¸„à¹‰à¸²/à¹€à¸ˆà¹‰à¸²à¸‚à¸­à¸‡à¸ªà¸§à¸™à¹ƒà¸«à¹‰à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡
3. **à¹„à¸‹à¸•à¹Œ/à¸‚à¸™à¸²à¸”**: à¸ˆà¸±à¸”à¸£à¸°à¹€à¸šà¸µà¸¢à¸šà¸‚à¸™à¸²à¸”à¹ƒà¸«à¹‰à¹€à¸›à¹‡à¸™à¸£à¸¹à¸›à¹à¸šà¸šà¸—à¸µà¹ˆà¸ªà¸¡à¹ˆà¸³à¹€à¸ªà¸¡à¸­ (à¹€à¸Šà¹ˆà¸™ "15\"", "10\"", "à¸‚à¸™à¸²à¸”à¹€à¸¥à¹‡à¸", "à¸‚à¸™à¸²à¸”à¸à¸¥à¸²à¸‡")
4. **à¸£à¸¹à¸›à¸ à¸²à¸ž**: à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š URL à¸£à¸¹à¸›à¸ à¸²à¸žà¹ƒà¸«à¹‰à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡
5. **à¸«à¸¡à¸§à¸”à¸«à¸¡à¸¹à¹ˆ**: à¸ˆà¸±à¸”à¸£à¸°à¹€à¸šà¸µà¸¢à¸šà¸«à¸¡à¸§à¸”à¸«à¸¡à¸¹à¹ˆà¹ƒà¸«à¹‰à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡ (à¹„à¸¡à¹‰à¸›à¸£à¸°à¸”à¸±à¸š, à¹„à¸¡à¹‰à¸¥à¹‰à¸­à¸¡, à¹„à¸¡à¹‰à¸”à¸­à¸, à¹„à¸¡à¹‰à¹ƒà¸š, à¹à¸„à¸„à¸•à¸±à¸ª, à¸šà¸­à¸™à¹„à¸‹, à¸à¸¥à¹‰à¸§à¸¢à¹„à¸¡à¹‰)
6. **à¸£à¸²à¸„à¸²**: à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸£à¸²à¸„à¸²à¹ƒà¸«à¹‰à¹€à¸›à¹‡à¸™à¸•à¸±à¸§à¹€à¸¥à¸‚à¸—à¸µà¹ˆà¸ªà¸¡à¹€à¸«à¸•à¸¸à¸ªà¸¡à¸œà¸¥ (à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µà¸£à¸²à¸„à¸² à¹ƒà¸«à¹‰à¹ƒà¸ªà¹ˆ null)
7. **à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Supplier**: à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹€à¸šà¸­à¸£à¹Œà¹‚à¸—à¸£, à¸—à¸µà¹ˆà¸­à¸¢à¸¹à¹ˆà¹ƒà¸«à¹‰à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡
8. **à¸¥à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸‹à¹‰à¸³à¸‹à¹‰à¸­à¸™**: à¸£à¸§à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸‹à¹‰à¸³à¸à¸±à¸™

âš ï¸ à¸ªà¸³à¸„à¸±à¸: à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸•à¹‰à¸­à¸‡à¸ˆà¸±à¸”à¸£à¸°à¹€à¸šà¸µà¸¢à¸šà¹ƒà¸«à¹‰à¸„à¸£à¸šà¸–à¹‰à¸§à¸™ (à¸Šà¸·à¹ˆà¸­à¸•à¹‰à¸™à¹„à¸¡à¹‰, à¸Šà¸·à¹ˆà¸­à¸£à¹‰à¸²à¸™, à¹„à¸‹à¸•à¹Œ, à¸£à¸¹à¸›à¸ à¸²à¸ž) à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰ Admin à¸ªà¸²à¸¡à¸²à¸£à¸–à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹à¸¥à¸° approve à¹„à¸”à¹‰à¸‡à¹ˆà¸²à¸¢

à¸•à¸­à¸šà¹€à¸›à¹‡à¸™ JSON format à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸ªà¹ˆà¸‡à¸¡à¸² à¹à¸•à¹ˆà¹€à¸›à¹‡à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹à¸¥à¸°à¸ˆà¸±à¸”à¸£à¸°à¹€à¸šà¸µà¸¢à¸šà¹à¸¥à¹‰à¸§

à¸•à¸­à¸šà¹€à¸›à¹‡à¸™ JSON à¸¥à¹‰à¸§à¸™à¹† à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™ à¸«à¹‰à¸²à¸¡à¹ƒà¸ªà¹ˆà¹‚à¸„à¹‰à¸”à¸šà¸¥à¹‡à¸­à¸`;

      const validatedResult = await aiService.analyzeText(validationPrompt);

      return validatedResult || extractedData;
    } catch (error) {
      console.error('Validation error:', error);
      return extractedData; // Return original if validation fails
    }
  }

  // Analyze pasted text from Facebook posts (manual input)
  async analyzePastedText(text, sourceUrl = null) {
    try {
      console.log(`ðŸ¤– AI Agent: Analyzing pasted text (length: ${text.length})`);

      // Use AI to analyze and extract plant data from pasted text
      const aiPrompt = `à¸„à¸¸à¸“à¹€à¸›à¹‡à¸™ AI Agent à¸—à¸µà¹ˆà¸Šà¹ˆà¸§à¸¢à¹à¸à¸°à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸•à¹‰à¸™à¹„à¸¡à¹‰à¹à¸¥à¸°à¸£à¸²à¸„à¸²à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸—à¸µà¹ˆ copy-paste à¸ˆà¸²à¸ Facebook

âš ï¸ à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸: à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸™à¸µà¹‰à¸¡à¸²à¸ˆà¸²à¸ Facebook Post à¸—à¸µà¹ˆ admin copy-paste à¸¡à¸²

ðŸŽ¯ à¸ªà¸³à¸„à¸±à¸à¸¡à¸²à¸: 
- à¹à¸à¸°à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸•à¹‰à¸™à¹„à¸¡à¹‰à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸—à¸µà¹ˆà¸žà¸šà¹ƒà¸™à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡
- à¹à¸à¸°à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸£à¸²à¸„à¸² (à¸–à¹‰à¸²à¸¡à¸µ)
- à¹à¸à¸°à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸‚à¸™à¸²à¸”/à¹„à¸‹à¸•à¹Œ (à¸–à¹‰à¸²à¸¡à¸µ)
- à¹à¸à¸°à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸•à¸´à¸”à¸•à¹ˆà¸­ (à¸Šà¸·à¹ˆà¸­ à¹€à¸šà¸­à¸£à¹Œà¹‚à¸—à¸£ à¸—à¸µà¹ˆà¸­à¸¢à¸¹à¹ˆ Line ID)
- à¹à¸à¸°à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸šà¸£à¸´à¸à¸²à¸£ (à¸›à¸¥à¸¹à¸ à¸ªà¹ˆà¸‡ à¹€à¸à¹‡à¸šà¹€à¸‡à¸´à¸™à¸›à¸¥à¸²à¸¢à¸—à¸²à¸‡)
- à¸§à¸±à¸™à¸—à¸µà¹ˆà¹‚à¸žà¸ªà¸•à¹Œ (à¸–à¹‰à¸²à¸¡à¸µ à¹€à¸Šà¹ˆà¸™ "15 à¸™à¸²à¸—à¸µ", "1 à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡", "1 à¸§à¸±à¸™")

à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸žà¸š:
- à¸Šà¸·à¹ˆà¸­à¸•à¹‰à¸™à¹„à¸¡à¹‰ (à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡)
- à¹€à¸šà¸­à¸£à¹Œà¹‚à¸—à¸£à¸¨à¸±à¸žà¸—à¹Œ (à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸•à¸´à¸”à¸•à¹ˆà¸­)
- à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸•à¸´à¸”à¸•à¹ˆà¸­ (à¸Šà¸·à¹ˆà¸­ à¹€à¸šà¸­à¸£à¹Œà¹‚à¸—à¸£ à¸—à¸µà¹ˆà¸­à¸¢à¸¹à¹ˆ Line ID)
- à¸£à¸²à¸„à¸² (à¸–à¹‰à¸²à¸¡à¸µ - à¸­à¸²à¸ˆà¹„à¸¡à¹ˆà¸¡à¸µà¸£à¸²à¸„à¸²à¹ƒà¸™à¸šà¸²à¸‡à¹‚à¸žà¸ªà¸•à¹Œ)
- à¸‚à¸™à¸²à¸”/à¹„à¸‹à¸•à¹Œ (à¸–à¹‰à¸²à¸¡à¸µ à¹€à¸Šà¹ˆà¸™ "80 à¹€à¸‹à¸™ - 3 à¹€à¸¡à¸•à¸£", "2-2.20-2.50-3-3.50-4 à¹€à¸¡à¸•à¸£")
- à¸šà¸£à¸´à¸à¸²à¸£ (à¸›à¸¥à¸¹à¸ à¸ªà¹ˆà¸‡ à¹€à¸à¹‡à¸šà¹€à¸‡à¸´à¸™à¸›à¸¥à¸²à¸¢à¸—à¸²à¸‡)

âš ï¸ à¸£à¸²à¸„à¸²à¸­à¸²à¸ˆà¹„à¸¡à¹ˆà¸¡à¸µ: à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µà¸£à¸²à¸„à¸² à¹ƒà¸«à¹‰à¹ƒà¸ªà¹ˆ price à¹€à¸›à¹‡à¸™ null à¸«à¸£à¸·à¸­ 0
âš ï¸ à¹€à¸à¹‡à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸•à¹‰à¸™à¹„à¸¡à¹‰à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸—à¸µà¹ˆà¸žà¸š: à¹à¸¡à¹‰à¹„à¸¡à¹ˆà¸¡à¸µà¸£à¸²à¸„à¸²à¸à¹‡à¹€à¸à¹‡à¸šà¹„à¸§à¹‰

à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸—à¸µà¹ˆ copy-paste à¸¡à¸²:
${text}

à¸à¸£à¸¸à¸“à¸²à¹à¸à¸°à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸•à¹‰à¸™à¹„à¸¡à¹‰à¹à¸¥à¸°à¸£à¸²à¸„à¸²à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸‚à¹‰à¸²à¸‡à¸•à¹‰à¸™ à¹à¸¥à¸°à¹à¸›à¸¥à¸‡à¹€à¸›à¹‡à¸™ JSON format à¸•à¸²à¸¡à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¸™à¸µà¹‰:

{
  "supplier": {
    "name": "à¸Šà¸·à¹ˆà¸­à¸£à¹‰à¸²à¸™à¸„à¹‰à¸²/à¹€à¸ˆà¹‰à¸²à¸‚à¸­à¸‡à¸ªà¸§à¸™/à¸œà¸¹à¹‰à¸‚à¸²à¸¢",
    "location": "à¸—à¸µà¹ˆà¸­à¸¢à¸¹à¹ˆ (à¸–à¹‰à¸²à¸¡à¸µ)",
    "phone": "à¹€à¸šà¸­à¸£à¹Œà¹‚à¸—à¸£ (à¸–à¹‰à¸²à¸¡à¸µ)",
    "lineId": "Line ID (à¸–à¹‰à¸²à¸¡à¸µ)",
    "website": "${sourceUrl || 'Facebook Post'}"
  },
  "plants": [
    {
      "name": "à¸Šà¸·à¹ˆà¸­à¸•à¹‰à¸™à¹„à¸¡à¹‰",
      "scientificName": "à¸Šà¸·à¹ˆà¸­à¸§à¸´à¸—à¸¢à¸²à¸¨à¸²à¸ªà¸•à¸£à¹Œ (à¸–à¹‰à¸²à¸¡à¸µ)",
      "category": "à¸«à¸¡à¸§à¸”à¸«à¸¡à¸¹à¹ˆ (à¹„à¸¡à¹‰à¸›à¸£à¸°à¸”à¸±à¸š, à¹„à¸¡à¹‰à¸¥à¹‰à¸­à¸¡, à¹„à¸¡à¹‰à¸”à¸­à¸, à¹„à¸¡à¹‰à¹ƒà¸š, à¹à¸„à¸„à¸•à¸±à¸ª, à¸šà¸­à¸™à¹„à¸‹, à¸à¸¥à¹‰à¸§à¸¢à¹„à¸¡à¹‰)",
      "price": à¸£à¸²à¸„à¸² (à¸•à¸±à¸§à¹€à¸¥à¸‚ à¸«à¸£à¸·à¸­ null à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µà¸£à¸²à¸„à¸²),
      "size": "à¸‚à¸™à¸²à¸” (à¸–à¹‰à¸²à¸¡à¸µ à¹€à¸Šà¹ˆà¸™ '80 à¹€à¸‹à¸™ - 3 à¹€à¸¡à¸•à¸£', '2-2.20-2.50-3-3.50-4 à¹€à¸¡à¸•à¸£')",
      "description": "à¸„à¸³à¸­à¸˜à¸´à¸šà¸²à¸¢ (à¸–à¹‰à¸²à¸¡à¸µ)",
      "imageUrl": null,
      "postDate": "à¸§à¸±à¸™à¸—à¸µà¹ˆà¹‚à¸žà¸ªà¸•à¹Œ (à¸–à¹‰à¸²à¸¡à¸µ à¹€à¸Šà¹ˆà¸™ '15 à¸™à¸²à¸—à¸µ', '1 à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡', '1 à¸§à¸±à¸™')",
      "stockAvailable": true/false (à¸–à¹‰à¸²à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹„à¸”à¹‰)
    }
  ],
  "services": ["à¸›à¸¥à¸¹à¸", "à¸ªà¹ˆà¸‡", "à¹€à¸à¹‡à¸šà¹€à¸‡à¸´à¸™à¸›à¸¥à¸²à¸¢à¸—à¸²à¸‡"] (à¸–à¹‰à¸²à¸¡à¸µ),
  "confidence": 0.0-1.0 (à¸„à¸§à¸²à¸¡à¸¡à¸±à¹ˆà¸™à¹ƒà¸ˆà¹ƒà¸™à¸à¸²à¸£à¹à¸à¸°à¸‚à¹‰à¸­à¸¡à¸¹à¸¥)
}

âš ï¸ à¸ªà¸³à¸„à¸±à¸: à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µà¸£à¸²à¸„à¸² à¹ƒà¸«à¹‰à¹ƒà¸ªà¹ˆ price à¹€à¸›à¹‡à¸™ null à¸«à¸£à¸·à¸­ 0 (à¸«à¹‰à¸²à¸¡à¹ƒà¸ªà¹ˆà¸£à¸²à¸„à¸²à¹à¸šà¸šà¸ªà¸¸à¹ˆà¸¡)
âš ï¸ à¹€à¸à¹‡à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸•à¹‰à¸™à¹„à¸¡à¹‰à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸—à¸µà¹ˆà¸žà¸š à¹à¸¡à¹‰à¹„à¸¡à¹ˆà¸¡à¸µà¸£à¸²à¸„à¸²à¸à¹‡à¹€à¸à¹‡à¸šà¹„à¸§à¹‰
âš ï¸ à¹à¸à¸°à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸šà¸­à¸£à¹Œà¹‚à¸—à¸£ Line ID à¹à¸¥à¸°à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸•à¸´à¸”à¸•à¹ˆà¸­à¹ƒà¸«à¹‰à¸„à¸£à¸šà¸–à¹‰à¸§à¸™

à¸•à¸­à¸šà¹€à¸›à¹‡à¸™ JSON à¸¥à¹‰à¸§à¸™à¹† à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™ à¸«à¹‰à¸²à¸¡à¹ƒà¸ªà¹ˆà¹‚à¸„à¹‰à¸”à¸šà¸¥à¹‡à¸­à¸ (à¹€à¸Šà¹ˆà¸™ code fences) à¸«à¸£à¸·à¸­à¸„à¸³à¸­à¸˜à¸´à¸šà¸²à¸¢à¸­à¸·à¹ˆà¸™à¹†`;

      const aiResult = await aiService.analyzeText(aiPrompt);

      if (!aiResult || !aiResult.plants) {
        throw new Error('AI failed to extract plant data from pasted text');
      }

      // Validate and clean data using AI
      const validatedData = await this.validateAndCleanData(aiResult);

      // Save to database
      const savedData = await this.saveScrapingResults(null, sourceUrl || 'Facebook Post (Pasted)', validatedData);

      return {
        success: true,
        data: savedData,
        rawData: {
          textLength: text.length,
          method: 'pasted-text'
        }
      };

    } catch (error) {
      console.error('âŒ AI Agent Error (Pasted Text):', error);
      throw error;
    }
  }

  // Save scraping results to database
  async saveScrapingResults(websiteId, url, data) {
    const jobId = `job_${Date.now()}_${uuidv4()}`;

    try {
      // 1. Create scraping job
      await pool.query(`
        INSERT INTO scraping_jobs (id, website_id, url, status, started_at)
        VALUES ($1, $2, $3, $4, NOW())
      `, [jobId, websiteId || null, url, 'processing']);

      // 2. Save scraping results as PENDING (waiting for admin approval)
      // Don't save to plants/suppliers yet - wait for approval
      const savedPlants = [];
      if (data.plants && Array.isArray(data.plants)) {
        for (const plantData of data.plants) {
          try {
            // Save scraping result as PENDING (waiting for admin approval)
            const resultId = `result_${Date.now()}_${uuidv4()}`;
            // à¸–à¹‰à¸²à¸¡à¸µà¸£à¸²à¸„à¸² à¹ƒà¸Šà¹‰à¸£à¸²à¸„à¸² à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µ à¹ƒà¸Šà¹‰ null (à¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆ 0)
            const plantPrice = (plantData.price && plantData.price > 0) ? plantData.price : null;

            // Store all data for admin review (including supplier info)
            // Don't create plant/supplier yet - wait for approval
            await pool.query(`
              INSERT INTO scraping_results (
                id, job_id, plant_id, supplier_id, plant_name, price, size, 
                raw_data, confidence, status, image_url,
                supplier_name, supplier_phone, supplier_location
              )
              VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14)
            `, [
              resultId,
              jobId,
              null, // plant_id = null (will be set after approval)
              null, // supplier_id = null (will be set after approval)
              plantData.name,
              plantPrice,
              plantData.size || null,
              JSON.stringify(plantData),
              data.confidence || 0.8,
              'pending', // Status: pending (waiting for approval)
              plantData.imageUrl || null,
              data.supplier?.name || null,
              data.supplier?.phone || null,
              data.supplier?.location || null
            ]);

            // Don't save to plants/suppliers yet - wait for admin approval
            // This will be done in the approval endpoint

            savedPlants.push({
              resultId,
              plantName: plantData.name,
              price: plantPrice,
              size: plantData.size,
              imageUrl: plantData.imageUrl,
              supplierName: data.supplier?.name
            });
          } catch (error) {
            console.error(`Error saving plant ${plantData.name}:`, error);
          }
        }
      }

      // 4. Update job status
      await pool.query(`
        UPDATE scraping_jobs
        SET status = $1, completed_at = NOW(), result = $2
        WHERE id = $3
      `, ['completed', JSON.stringify({ plants: savedPlants, count: savedPlants.length }), jobId]);

      return {
        jobId,
        plants: savedPlants,
        count: savedPlants.length,
        confidence: data.confidence || 0.5,
        status: 'pending' // All results are pending approval
      };

    } catch (error) {
      // Update job status to failed
      await pool.query(`
        UPDATE scraping_jobs
        SET status = $1, completed_at = NOW(), result = $2
        WHERE id = $3
      `, ['failed', JSON.stringify({ error: error.message }), jobId]);
      throw error;
    }
  }
  // Search from Google Maps and save as candidates
  async searchPlacesAndSave(keywords, filterWholesale = false) {
    // 1. Handle single keyword or array
    const keywordList = Array.isArray(keywords) ? keywords : [keywords];
    const jobId = `job_maps_${Date.now()}_${uuidv4()}`;
    const allSavedItems = [];
    let totalProcessed = 0;

    try {
      console.log(`ðŸ¤– AI Agent: Starting Google Maps batch search for ${keywordList.length} keywords`);

      // Create Job
      await pool.query(`
        INSERT INTO scraping_jobs (id, website_id, url, status, started_at)
        VALUES ($1, $2, $3, $4, NOW())
      `, [jobId, null, `Maps Batch Search (${keywordList.length} keywords)`, 'processing']);

      // 2. Loop through keywords
      for (const keyword of keywordList) {
        if (!keyword || !keyword.trim()) continue;

        try {
          console.log(`ðŸ“ Searching for: "${keyword}"`);
          const places = await googleMapsService.searchPlaces(keyword);

          if (places.length === 0) continue;

          // 3. Process each place
          for (const place of places) {
            totalProcessed++;

            // Deduplication (Check by Place ID)
            if (place.placeId) {
              const existing = await pool.query(
                `SELECT id FROM scraping_results WHERE raw_data->>'placeId' = $1 AND status != 'rejected'`,
                [place.placeId]
              );
              if (existing.rows.length > 0) {
                console.log(`Evaluate duplicate: ${place.name} (Skipping)`);
                continue;
              }
            }

            // Fetch Details (Phone, etc.)
            let detailedPlace = place;
            if (place.placeId) {
              const details = await googleMapsService.getPlaceDetails(place.placeId);
              if (details) {
                // Merge details
                detailedPlace = { ...place, ...details };
                // Specific phone formatting if needed
                detailedPlace.phone = details.formatted_phone_number || details.international_phone_number || place.phone;
              }
            }

            // AI Filtering (Wholesale check)
            if (filterWholesale) {
              const isWholesale = await this.checkIfWholesale(detailedPlace);
              if (!isWholesale) {
                console.log(`ðŸš« AI Filtered out: ${detailedPlace.name} (Not wholesale)`);
                continue;
              }
            }

            // Save Result
            const resultId = `result_${Date.now()}_${uuidv4()}`;
            await pool.query(`
              INSERT INTO scraping_results (
                id, job_id, plant_id, supplier_id, plant_name, price, size, 
                raw_data, confidence, status, image_url,
                supplier_name, supplier_phone, supplier_location
              )
              VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14)
            `, [
              resultId,
              jobId,
              null,
              null,
              `New Supplier Found`, // Generic name
              null,
              null,
              JSON.stringify(detailedPlace),
              0.95,
              'pending',
              null, // Image URL could be fetched from Photo References later
              detailedPlace.name,
              detailedPlace.phone || null,
              detailedPlace.formatted_address || detailedPlace.location
            ]);

            allSavedItems.push({
              resultId,
              supplierName: detailedPlace.name,
              location: detailedPlace.formatted_address
            });
          }

        } catch (searchErr) {
          console.error(`Error searching keyword "${keyword}":`, searchErr);
        }
      }

      // 4. Update Job
      await pool.query(`
        UPDATE scraping_jobs
        SET status = $1, completed_at = NOW(), result = $2
        WHERE id = $3
      `, ['completed', JSON.stringify({ items: allSavedItems, count: allSavedItems.length }), jobId]);

      return {
        success: true,
        count: allSavedItems.length,
        processed: totalProcessed,
        jobId,
        items: allSavedItems
      };

    } catch (error) {
      console.error('âŒ Maps Batch Search Error:', error);
      // Update job status to failed
      await pool.query(`
        UPDATE scraping_jobs
        SET status = $1, completed_at = NOW(), result = $2
        WHERE id = $3
      `, ['failed', JSON.stringify({ error: error.message }), jobId]);
      throw error;
    }
  }

  // AI Helper: Check if place is a wholesale supplier
  async checkIfWholesale(place) {
    // Simple fast check: check types or name
    const keywords = ['wholesale', 'supplies', 'garden center', 'florist', 'market', 'farm', 'à¸‚à¸²à¸¢à¸ªà¹ˆà¸‡', 'à¸•à¸¥à¸²à¸”', 'à¸ªà¸§à¸™', 'à¸Ÿà¸²à¸£à¹Œà¸¡'];
    const nameLower = place.name.toLowerCase();

    // 1. Basic Keyword Match
    const hasKeyword = keywords.some(k => nameLower.includes(k));
    if (hasKeyword) return true; // High likelihood

    // 2. AI Analysis for ambiguous cases (using existing aiService)
    try {
      const prompt = `Analyzer this business: "${place.name}". 
      Categories: ${JSON.stringify(place.types)}. 
      Reviews: ${JSON.stringify(place.reviews?.slice(0, 2) || [])}.
      Is this significantly likely to be a plant wholesaler, plant market, or large garden supplier?
      Answer YES or NO only.`;

      const aiResponse = await aiService.analyzeText(prompt);
      // aiService returns JSON usually, but here we just want a string check if analyzeText returns string.
      // Assuming analyzeText returns object, we might need a simpler calls. 
      // For safety, let's stick to keyword matching + Types for now to save tokens/time,
      // as "Wholesale" filter implies strict "Wholesale" intent.

      // Let's rely on Types
      const validTypes = ['florist', 'store', 'point_of_interest', 'establishment'];
      if (!place.types || place.types.length === 0) return true; // Default keep

      return place.types.some(t => validTypes.includes(t));
    } catch (e) {
      return true; // Fail safe: keep it
    }
  }
}

module.exports = new AgentService();
